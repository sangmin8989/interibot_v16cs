import { NextRequest, NextResponse } from 'next/server';
import OpenAI from 'openai';
import { ChatAnalysisResult, ChatAnalyzeResponse, ChatMessage, PhotoAnalysisResult } from '@/lib/analysis/v5-ultimate/types';
import { CHAT_ANALYSIS_PROMPT } from '@/lib/analysis/v5-ultimate/prompts';
import { callAIWithLimit } from '@/lib/api/ai-call-limiter';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export async function POST(request: NextRequest): Promise<NextResponse<ChatAnalyzeResponse>> {
  try {
    const body = await request.json();
    const { messages, photoAnalysis }: { messages: ChatMessage[]; photoAnalysis: PhotoAnalysisResult | null } = body;

    if (!messages || messages.length === 0) {
      return NextResponse.json({ success: false, error: 'ëŒ€í™” ë‚´ìš©ì´ í•„ìš”í•©ë‹ˆë‹¤.' }, { status: 400 });
    }

    // ì‚¬ìš©ì ë©”ì‹œì§€ë§Œ ì¶”ì¶œ
    const userMessages = messages.filter(m => m.role === 'user');
    const questionIndex = userMessages.length;
    
    // 5ê°œ ì§ˆë¬¸ ì™„ë£Œ ì²´í¬
    const isComplete = questionIndex >= 5;

    // ëŒ€í™” ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    const conversationText = messages
      .map(m => `${m.role === 'user' ? 'ê³ ê°' : 'ìƒë‹´ì‚¬'}: ${m.content}`)
      .join('\n');

    // GPT-4o-mini ë¶„ì„ í˜¸ì¶œ (ì§ˆë¬¸ ìƒì„± ì œê±°, ì˜¤ì§ ë¶„ì„ë§Œ)
    let response;
    try {
      // ë¶„ì„ ì „ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì§ˆë¬¸ ìƒì„± ì§€ì‹œ ì œê±°)
      const analysisSystemPrompt = `ë‹¹ì‹ ì€ ì¸í…Œë¦¬ì–´ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.
ê³ ê°ê³¼ì˜ ëŒ€í™”ë¥¼ ë¶„ì„í•˜ì—¬ ì¸í…Œë¦¬ì–´ ì„±í–¥ì„ íŒŒì•…í•©ë‹ˆë‹¤.

ë¶„ì„ í•­ëª©:
1. extractedTags: ëŒ€í™”ì—ì„œ ì¶”ì¶œí•œ ì„±í–¥ íƒœê·¸ (ë°°ì—´)
2. cleaningStyle: ì²­ì†Œ ìŠ¤íƒ€ì¼ (diligent/moderate/lazy/system_needed ì¤‘ í•˜ë‚˜)
3. spaceInterests: ê´€ì‹¬ ê³µê°„ (living/kitchen/bedroom/bathroom/study/entrance ë°°ì—´)
4. budgetRange: ì˜ˆì‚° ë²”ìœ„ ({"min": ìˆ«ì, "max": ìˆ«ì} ë˜ëŠ” null)
5. familyInfo: ê°€ì¡± ì •ë³´ ({"totalMembers": ìˆ«ì, "hasChild": boolean, "hasElderly": boolean, "hasPet": "dog"/"cat"/"both"/"none"} ë˜ëŠ” null)
6. hiddenNeeds: ëŒ€í™”ì—ì„œ ë°œê²¬í•œ ìˆ¨ì€ ë‹ˆì¦ˆ (ë°°ì—´)
7. confidence: ë¶„ì„ ì‹ ë¢°ë„ (0.0-1.0)

ì‚¬ìš© ê°€ëŠ¥í•œ íƒœê·¸:
- ìŠ¤íƒ€ì¼: MODERN_LOVER, NATURAL_LOVER, MINIMAL_LOVER, CLASSIC_LOVER, SCANDINAVIAN_LOVER, VINTAGE_LOVER
- ìƒí™œ: HAS_CHILD, HAS_INFANT, HAS_TEEN, HAS_PET_DOG, HAS_PET_CAT, REMOTE_WORK, BOOKWORM, PLANT_LOVER, COOKING_LOVER, GUEST_FREQUENT
- ë‹ˆì¦ˆ: STORAGE_NEED, LIGHTING_NEED, CLEANING_SYSTEM_NEED, SOUNDPROOF_NEED, SAFETY_NEED, VENTILATION_NEED
- ìƒíƒœ: WELL_ORGANIZED, NEEDS_ORGANIZATION, SPACE_EFFICIENT, SPACE_WASTED
- ì˜ˆì‚°: BUDGET_STRICT, BUDGET_MODERATE, BUDGET_FLEXIBLE, VALUE_PROTECTION

ëŒ€í™”ì—ì„œ ì§ì ‘ ì–¸ê¸‰í•˜ì§€ ì•Šì•˜ì§€ë§Œ ì¶”ë¡  ê°€ëŠ¥í•œ ê²ƒë„ í¬í•¨í•©ë‹ˆë‹¤.
í™•ì‹¤í•˜ì§€ ì•Šì€ ê²ƒì€ nullë¡œ ë‚¨ê²¨ë‘ì„¸ìš”.

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{
  "extractedTags": ["HAS_CHILD", "CLEANING_SYSTEM_NEED"],
  "cleaningStyle": "lazy",
  "spaceInterests": ["living", "kitchen"],
  "budgetRange": {"min": 3000, "max": 5000},
  "familyInfo": {"totalMembers": 4, "hasChild": true, "hasElderly": false, "hasPet": "none"},
  "hiddenNeeds": ["ì²­ì†Œ ì‹œê°„ ë¶€ì¡± - ì‹œìŠ¤í…œ í•„ìš”"],
  "confidence": 0.75
}`;

      // Phase 4: AI í˜¸ì¶œ ë˜í¼ ì ìš© (enableLimit=false)
      const enableLimit = process.env.NEXT_PUBLIC_AI_RATE_LIMIT === 'true';
      const sessionId = request.headers.get('x-session-id') || undefined;
      
      response = await callAIWithLimit({
        sessionId,
        action: 'CHAT',
        prompt: { systemPrompt: analysisSystemPrompt, conversationText },
        enableLimit: false, // ğŸ”’ Phase 4: ë°˜ë“œì‹œ false
        aiCall: async () => {
          return await openai.chat.completions.create({
            model: 'gpt-4o-mini',
            messages: [
              {
                role: 'system',
                content: analysisSystemPrompt
              },
              {
                role: 'user',
                content: `ë‹¤ìŒ ëŒ€í™”ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:\n\n${conversationText}`
              }
            ],
            max_tokens: 800,
            temperature: 0.3,
          });
        },
      });
    } catch (apiError) {
      console.error('OpenAI API í˜¸ì¶œ ì—ëŸ¬:', apiError);
      return NextResponse.json({ 
        success: false, 
        error: apiError instanceof Error ? apiError.message : 'OpenAI API í˜¸ì¶œ ì‹¤íŒ¨',
        isComplete: false
      }, { status: 500 });
    }

    const content = response.choices[0]?.message?.content;
    
    if (!content) {
      console.error('GPT ì‘ë‹µì´ ë¹„ì–´ìˆìŒ:', response);
      return NextResponse.json({ 
        success: false, 
        error: 'ë¶„ì„ ê²°ê³¼ë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.',
        isComplete: false
      }, { status: 500 });
    }

    // JSON íŒŒì‹±
    let analysis: ChatAnalysisResult;
    let nextQuestion: string | undefined = undefined;
    
    try {
      const jsonMatch = content.match(/\{[\s\S]*\}/);
      if (!jsonMatch) {
        console.error('JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŒ. ì›ë³¸ ì‘ë‹µ:', content);
        throw new Error('JSON not found in response');
      }
      const parsed = JSON.parse(jsonMatch[0]);
      
      // ë¶„ì„ ê²°ê³¼ ì¶”ì¶œ
      analysis = {
        extractedTags: parsed.extractedTags || [],
        cleaningStyle: parsed.cleaningStyle || 'moderate',
        spaceInterests: parsed.spaceInterests || [],
        budgetRange: parsed.budgetRange || null,
        familyInfo: parsed.familyInfo || null,
        hiddenNeeds: parsed.hiddenNeeds || [],
        confidence: typeof parsed.confidence === 'number' ? parsed.confidence : 0.5
      };
      
    } catch (parseError) {
      console.error('JSON íŒŒì‹± ì—ëŸ¬:', parseError);
      console.error('ì›ë³¸ ì‘ë‹µ:', content);
      // ê¸°ë³¸ê°’ ë°˜í™˜
      analysis = {
        extractedTags: [],
        cleaningStyle: 'moderate',
        spaceInterests: [],
        budgetRange: null,
        familyInfo: null,
        hiddenNeeds: [],
        confidence: 0.5
      };
    }

    // ì§ˆë¬¸ ìƒì„±ì€ ì§ˆë¬¸ ì—”ì§„ì—ì„œë§Œ ìˆ˜í–‰ (ì´ APIëŠ” ë¶„ì„ë§Œ ìˆ˜í–‰)
    // nextQuestionì€ ì œê±°ë¨ - ì§ˆë¬¸ ì—”ì§„ APIë¥¼ ë³„ë„ë¡œ í˜¸ì¶œí•´ì•¼ í•¨

    return NextResponse.json({
      success: true,
      analysis,
      isComplete: isComplete || false
    });

  } catch (error) {
    console.error('ëŒ€í™” ë¶„ì„ ì—ëŸ¬:', error);
    console.error('ì—ëŸ¬ ìŠ¤íƒ:', error instanceof Error ? error.stack : 'No stack trace');
    return NextResponse.json({ 
      success: false, 
      error: error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì—ëŸ¬',
      isComplete: false
    }, { status: 500 });
  }
}




