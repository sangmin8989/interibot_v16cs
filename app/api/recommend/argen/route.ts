import { NextRequest, NextResponse } from 'next/server'
import OpenAI from 'openai'
import { callAIWithLimit } from '@/lib/api/ai-call-limiter'

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
})

// ì•„ë¥´ì   ì œì‘ ê°€ëŠ¥ í•­ëª© ëª©ë¡
const ARGEN_ITEMS = [
  'ë¶™ë°•ì´ì¥',
  'ë“œë ˆìŠ¤ë£¸',
  'TVì¥',
  'ìˆ˜ë‚©ì¥',
  'í…œë°”ë³´ë“œ',
  'ê°„ì ‘ë“± ë°•ìŠ¤',
  'ê°€ë²½',
  'íŒŒí‹°ì…˜',
  'ì¤‘ë¬¸',
  'ì£¼ë°© ìƒë¶€ì¥',
  'ì£¼ë°© í•˜ë¶€ì¥',
  'í•„ë¦„',
  'ë„ì¥',
  'ë°©ìŒ íŒ¨ë„',
  'í¡ìŒ íŒ¨ë„',
]

export async function POST(request: NextRequest) {
  try {
    const { preferences, spaceInfo } = await request.json()

    if (!preferences) {
      return NextResponse.json(
        { error: 'ì„±í–¥ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.' },
        { status: 400 }
      )
    }

    // OpenAIë¥¼ ì‚¬ìš©í•˜ì—¬ ì„±í–¥ì— ë§ëŠ” ì•„ë¥´ì   ì œì‘ í•­ëª© ì¶”ì²œ
    const systemPrompt = `ë‹¹ì‹ ì€ ì•„ë¥´ì   ì¸í…Œë¦¬ë´‡ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ê³ ê°ì˜ ì„±í–¥ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•„ë¥´ì  ì—ì„œ ì œì‘ ê°€ëŠ¥í•œ í•­ëª©ì„ ì¶”ì²œí•˜ì„¸ìš”.

ì•„ë¥´ì   ì œì‘ ê°€ëŠ¥ í•­ëª©:
${ARGEN_ITEMS.join(', ')}

ê³ ê°ì˜ ì„±í–¥ì„ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì í•©í•œ 3~5ê°œ í•­ëª©ì„ ì¶”ì²œí•˜ë˜, ê°•ìš”í•˜ì§€ ì•Šê³  ìì—°ìŠ¤ëŸ½ê²Œ ì œì•ˆí•˜ì„¸ìš”.
JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:
{
  "recommendedItems": ["í•­ëª©1", "í•­ëª©2", "í•­ëª©3"],
  "reasoning": "ì¶”ì²œ ì´ìœ  (í•œêµ­ì–´)"
}`

    const userPrompt = `ì„±í–¥ ë¶„ì„ ê²°ê³¼:
${JSON.stringify(preferences, null, 2)}

ê³µê°„ ì •ë³´:
${JSON.stringify(spaceInfo, null, 2)}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•„ë¥´ì   ì œì‘ ê°€ëŠ¥ í•­ëª©ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.`

    // Phase 4: AI í˜¸ì¶œ ë˜í¼ ì ìš© (enableLimit=false)
    const enableLimit = process.env.NEXT_PUBLIC_AI_RATE_LIMIT === 'true';
    const sessionId = request.headers.get('x-session-id') || undefined;
    
    const response = await callAIWithLimit({
      sessionId,
      action: 'OPTION_RECOMMEND',
      prompt: { systemPrompt, userPrompt },
      enableLimit: false, // ğŸ”’ Phase 4: ë°˜ë“œì‹œ false
      aiCall: async () => {
        return await openai.chat.completions.create({
          model: 'gpt-3.5-turbo',
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: userPrompt },
          ],
          response_format: { type: 'json_object' },
          temperature: 0.7,
        });
      },
    })

    const result = JSON.parse(response.choices[0]?.message?.content || '{}')

    // ì¶”ì²œëœ í•­ëª©ì´ ì‹¤ì œ ì•„ë¥´ì   ì œì‘ ê°€ëŠ¥ í•­ëª©ì¸ì§€ ê²€ì¦
    const validatedItems = (result.recommendedItems || []).filter((item: string) =>
      ARGEN_ITEMS.some((argenItem) => item.includes(argenItem) || argenItem.includes(item))
    )

    return NextResponse.json({
      success: true,
      recommendedItems: validatedItems.length > 0 ? validatedItems : result.recommendedItems || [],
      reasoning: result.reasoning || '',
    })
  } catch (error) {
    console.error('ì•„ë¥´ì   ì¶”ì²œ ì˜¤ë¥˜:', error)
    
    // ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì¶”ì²œ ì œê³µ
    return NextResponse.json({
      success: true,
      recommendedItems: ['ë¶™ë°•ì´ì¥', 'ìˆ˜ë‚©ì¥', 'TVì¥'],
      reasoning: 'ê¸°ë³¸ ì¶”ì²œ í•­ëª©ì…ë‹ˆë‹¤.',
    })
  }
}

